{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 결합 및 부분 선택\n",
    "\n",
    "### 주요 내용\n",
    "\n",
    "1. 데이터 결합\n",
    "2. index, columns을 활용한 부분 선택 \n",
    "3. 조건을 활용한 관측치 선택\n",
    "\n",
    "<br>\n",
    "\n",
    "### 목표 \n",
    "1. 복수의 데이터를 적절한 방법으로 결합할 수 있다.\n",
    "2. 변수 이름 등을 활용하여 부분 데이터를 선택한다.\n",
    "3. 주제에 맞게 조건을 활용하여 부분 관측치를 선택한다. \n",
    "\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DataFrame 형식의 활용\n",
    "\n",
    "pandas는 데이터를 저장하는 형식 **DataFrame**을 중심으로 구성되어 있음  \n",
    "pandas의 다양한 함수를 활용해서 데이터를 불러오거나 저장할 수 있고, 분석 과정에서 필요한 전처리나 집계 작업도 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "DataFrame에서 각각의 열, 변수가 하나의 Series로 저장되어 있음  \n",
    "Series의 메서드와 DataFrame의 메서드 구분 필요  \n",
    "\n",
    "만약 직접 DataFrame을 만들어야 할 때는 *DataFrame( )* 과 딕셔너리를 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 딕셔너리를 활용한 DataFrame 생성\n",
    "df_own = pd.DataFrame({'FIRST' : ['A', 'B', 'C', 'D'],\n",
    "                       'SECOND': [7,6,5,8], \n",
    "                       'THIRD' : pd.date_range('2022-12-05', periods=4, freq='W-MON')}) # freq='W-MON' : 매주 월요일\n",
    "df_own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "## 2. 데이터 결합\n",
    "\n",
    "### 2.1. concat( )을 활용한 동일 구조 데이터 행 결합\n",
    "\n",
    "구조는 똑같고 기간이나 상품만 다른 여러 데이터가 있으면 pandas의 *concat()* 으로 결합해서 활용  \n",
    "함수 안에서 `axis=0`옵션을 활용해서 행 결합(아래로 이어 붙이기)을 할 수 있고, `axis=1`로 열 결합도 가능  \n",
    "`axis=0`이 기본값며 생략 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행 결합\n",
    "    ## 출처 : 국토교통부 실거래가(http://rtdown.molit.go.kr/)\n",
    "df_apt1 = pd.read_csv('data/아파트(매매)__실거래가_20210902153616.csv', skiprows=15, encoding='CP949')\n",
    "df_apt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apt2 = pd.read_csv('data/아파트(매매)__실거래가_20210902153636.csv', skiprows=15, encoding='CP949')\n",
    "df_apt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apt3 = pd.read_csv('data/아파트(매매)__실거래가_20210902153655.csv', skiprows=15, encoding='CP949')\n",
    "df_apt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_apt = pd.concat([df_apt1, df_apt2, df_apt3])\n",
    "df_apt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "> **DataFrame**에서 행 번호에 해당하는 **index**는 중요한 역할을 합니다.  \n",
    "예를 들어 아래처럼 index를 확인할 수 있고, 특정 index를 지정해서 관측치를 선택하는 것도 가능합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apt.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 0 관측치 선택\n",
    "df_apt.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결합 이전 기존 Index 활용으로 **0** 인덱스 관측치의 중복 발생  \n",
    "행 결합이나 정렬 이후 인덱스를 재지정하거나 초기화 필요 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_index()을 활용한 index 초기화\n",
    "    ## drop=True: 기존 인덱스를 변수로 추가할 지 버릴지 선택\n",
    "df_apt = df_apt.reset_index(drop=True)\n",
    "df_apt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 0 관측치 재선택\n",
    "df_apt.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [실습]  데이터 결합 및 인덱스 초기화\n",
    "\n",
    "출처 : [서울시 지하철 호선별 역별 승하차 인원수](http://data.seoul.go.kr/dataList/OA-12914/S/1/datasetView.do)\n",
    "\n",
    "1. `data`폴더의 `CARD_SUBWAY_MONTH_`로 시작하는 3개 데이터 확인하기  \n",
    "    \n",
    "\n",
    "\n",
    "2. 1.의 데이터를 각각 불러와서 저장하고, pd.concat()으로 행 결합하기(encoding='CP949' 활용)\n",
    "\n",
    "\n",
    "3. index 초기화 하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 읽어오기\n",
    "list_path = [\n",
    "    \"./data/CARD_SUBWAY_MONTH_201907.csv\",\n",
    "    \"./data/CARD_SUBWAY_MONTH_202007.csv\",\n",
    "    \"./data/CARD_SUBWAY_MONTH_202107.csv\"\n",
    "]\n",
    "targets = []\n",
    "for a in list_path:\n",
    "    df_subway1 = pd.read_csv(a, encoding='CP949')\n",
    "    targets.append(df_subway1)\n",
    "\n",
    "# 합치기 (행결합)\n",
    "df_subway = pd.concat(targets)\n",
    "# 인덱스 재설정\n",
    "df_subway = df_subway.reset_index(drop=True, inplace=True)\n",
    "display(df_subway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 파일 읽어오기\n",
    "df_subway1 = pd.read_csv(\"./data/CARD_SUBWAY_MONTH_201907.csv\", encoding='CP949')\n",
    "df_subway2 = pd.read_csv(\"./data/CARD_SUBWAY_MONTH_202007.csv\", encoding='CP949')\n",
    "df_subway3 = pd.read_csv(\"./data/CARD_SUBWAY_MONTH_202107.csv\", encoding='CP949')\n",
    "\n",
    "\n",
    "\n",
    "targets = [df_subway1, df_subway2, df_subway3]\n",
    "# 합치기 (행결합)\n",
    "df_subway = pd.concat(targets)\n",
    "# 인덱스 재설정\n",
    "df_subway = df_subway.reset_index(drop=True, inplace=True)\n",
    "display(df_subway)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [참고] glob과 for 반복문을 활용한 복수 데이터 처리\n",
    "\n",
    "**glob** 라이브러리의 *glob()* 을 활용하면 복수의 데이터 경로를 손쉽게 처리 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대상 파일 목록 생성\n",
    "#from pandas import read_csv\n",
    "import glob as g\n",
    "list_path  = g.glob('data/apt/*.csv')\n",
    "# target_path_list = []\n",
    "# for path in list_path:\n",
    "#     path\n",
    "\n",
    "\n",
    "targets = []\n",
    "for a in list_path:\n",
    "    df_subway1 = pd.read_csv(a, encoding='CP949', skiprows=15)\n",
    "    targets.append(df_subway1)\n",
    "\n",
    "# 합치기 (행결합)\n",
    "df_subway = pd.concat(targets)\n",
    "# # 인덱스 재설정\n",
    "df_subway.reset_index(drop=True, inplace=True)\n",
    "display(df_subway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for를 활용한 반복\n",
    "a = list()\n",
    "for path_ in file_list:\n",
    "    a.append(pd.read_csv(path_, skiprows=15, encoding='CP949'))\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 작업\n",
    "df_subway = pd.concat(a, axis=0).reset_index(drop=True)\n",
    "df_subway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.2. merge()를 활용한 KEY 변수 기준 결합 \n",
    "\n",
    "SQL의 JOIN, Excel의 VLOOKUP()과 같이 KEY 변수를 활용한 데이터 결합은 *merge()* 를 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 데이터 불러오기\n",
    "df_left  = pd.read_csv('data/data_left.csv')\n",
    "df_right = pd.read_csv('data/data_right.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "> key를 활용한 데이터 결합에서는 일치하는 key가 있는, 짝이 있는 관측치만 출력하는 것이 기본값으로 설정되어 있습니다. SQL에서는 이것을 **inner join**이라고 부릅니다.  \n",
    "\n",
    "*merge()* 에서 `how=` 옵션을 활용해서 다음과 같은 데이터 결합 방법 지정 \n",
    "\n",
    "+ `inner`: inner join. key 기준 일치하는 관측치만 포함\n",
    "+ `left`:  left join. inner join의 결과물과 왼쪽 데이터의 짝 없는 관측치 포함\n",
    "+ `right`: right join. inner join의 결과물과 오른쪽 데이터의 짝 없는 관측치 포함\n",
    "+ `outer`: full outer join. inner join과 양쪽 데이터의 짝이 없는 모든 관측치 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge()를 활용한 결합\n",
    "display(df_left, df_right)\n",
    "pd.merge(df_left, df_right, how='inner', on='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join\n",
    "pd.merge(df_left, df_right, how='left', on='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right join\n",
    "pd.merge(df_left, df_right, how='right', on='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full outer join\n",
    "pd.merge(df_left, df_right, how='outer', on='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "\n",
    "## 3. 데이터 부분 선택\n",
    "\n",
    "일반적인 비즈니스 데이터 분석에서 주제와 기간, 사이트, 제품, 공정 등 본인의 업무와 관련이 있는 일부 데이터만 선택하고 활용  \n",
    "SQL을 활용한 데이터 추출 과정과 별개로 Python에서 각 분석 과정에서 맞게 부분 데이터를 다시 선택하고 사용\n",
    "\n",
    "<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 데이터 불러오기\n",
    "import pandas as pd\n",
    "df_ins = pd.read_csv('data/insurance.csv')\n",
    "df_ins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3.1. .을 활용한 변수 선택\n",
    "\n",
    "DataFrame 뒤에 마침표(.)를 찍고 `Tab` 키를 눌러 DataFrame의 메서드들과 함께 변수이름을 확인 가능  \n",
    ".은 가장 간단한 변수 선택 방법이며 선택된 변수는 **Series** 형식으로 출력  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .을 활용한 하나의 변수 선택\n",
    "df_ins['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "### 3.2. 대괄호를 활용한 데이터 부분 선택\n",
    "\n",
    "DataFrame에 대괄호를 붙이고 슬라이스:로 관측치 번호를 지정하거나 따옴표''로 변수 이름을 넣어 데이터 부분을 선택 가능  \n",
    "변수 이름을 리스트 형식으로 묶어 넣어 여러개 변수를 한번에 선택 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관측치 선택\n",
    "df_ins[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 변수 선택 \n",
    "type(df_ins['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트를 활용한 복수 변수 선택\n",
    "target_list = ['age','smoker','charges']\n",
    "df_ins[target_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연속된 대괄호 활용가능\n",
    "# display(df_ins)\n",
    "# df_temp = df_ins[0:5]\n",
    "# display(df_temp)\n",
    "# df_temp[['age','smoker','charges']]\n",
    "df_ins[0:5][['age','smoker','charges']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### [실습]  \n",
    "\n",
    "1. 아래의 명령어를 실행해서 df_subway 데이터 생성하기 \n",
    "\n",
    "2. .columns 메서드를 활용해서 변수이름 확인하기\n",
    "\n",
    "3. 슬라이스를 활용하여 11~15번째 관측치 선택하기\n",
    "\n",
    "4. '사용일자', '역명', '하차총승객수' 세 변수 선택하기\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목적한 csv 파일을 읽어 DataFrame 만들고, df_subway 변수에 저장하기\n",
    "df_subway = pd.read_csv('./data/CARD_SUBWAY_MONTH_202107.csv', encoding='CP949')\n",
    "df_subway\n",
    "\n",
    "# columns 변수를 활용해서 columns 명 확인하기\n",
    "df_subway.columns\n",
    "\n",
    "# 슬라이싱을 활용하여 11~15번째 관측치(행) 선택하기\n",
    "df_subway[10:15]\n",
    "\n",
    "# '사용일자', '역명', '하차총승객수' 세 변수 선택하기\n",
    "df_subway[['사용일자', '역명', '하차총승객수']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3.3. loc과 iloc을 활용한 관측치/변수 선택\n",
    "\n",
    "loc은 행 이름(index)과 열 이름(column)으로 데이터에서 일부를 선택하고, iloc은 정수(integer) 형식의 행 번호, 열 번호를 활용  \n",
    "두 방법 모두 리스트[ ]나 슬라이스:를 활용한 방법을 지원\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습을 위해 원본 데이터를 복제(copy)하고 부분선택\n",
    "df_ins2 = df_ins.copy()[0:10]\n",
    "df_ins2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_ins' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 실습을 위해 인덱스를 별도로 지정\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_ins2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf_ins\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# df_ins2['idx'] = list(range(101, 111))\u001b[39;00m\n\u001b[0;32m      4\u001b[0m df_ins2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mj\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_ins' is not defined"
     ]
    }
   ],
   "source": [
    "# 실습을 위해 인덱스를 별도로 지정\n",
    "df_ins2 = df_ins.copy()[0:10]\n",
    "# df_ins2['idx'] = list(range(101, 111))\n",
    "df_ins2['idx'] = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "df_ins2.set_index('idx', inplace=True)\n",
    "df_ins2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "### 3.3.1. loc을 활용한 부분 선택\n",
    "\n",
    "loc은 실제로 눈에 보이는 index와 column을 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins2.loc['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins2.loc[['a', 'c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins2.loc['a':'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins2.loc[101:103, 'smoker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수이름 리스트 활용가능\n",
    "df_ins2.loc[101:103, ['smoker','region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수이름 슬라이스:를 활용 가능 \n",
    "df_ins2.loc[101:103, 'smoker':'charges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 관측치 선택할 때는 :\n",
    "df_ins2.loc[:, 'smoker']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "### 3.2.2. iloc을 활용한 부분 선택\n",
    "\n",
    "iloc은 이름과 상관없이 정수로 표현한 위치, 번호를 활용하며 리스트나 슬라이스 활용 방법은 loc과 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins2.iloc[0:3, [0,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [실습] \n",
    "\n",
    "1. df_pr에서 index 기준 '3'의 'Weight' 확인하기\n",
    "2. df_pr에서 index 기준 '11~15'의 'Age'부터 'Exercise'까지 선택하기\n",
    "3. df_pr에서 첫번째 ~ 다섯번째 관측치와 다섯번째 ~ 열번째 변수 선택하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr = pd.read_csv('data/PulseRates.csv')\n",
    "df_pr.loc[3, 'Weight']\n",
    "df_pr.loc[11:15, 'Age':'Exercise']\n",
    "df_pr.iloc[0:5, 4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. 함수를 활용한 여러 변수 선택 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter( ) 메서드에서 변수 이름 패턴을 활용한 선택 \n",
    "df_ins.filter(regex='e')\n",
    "    ## regex :  정규표현식(regular expression)\n",
    "    ## '^s' : 's'로 시작하는 이름/텍스트\n",
    "    ## 's$' : 's'로 끝나는 이름/텍스트\n",
    "    ## 's' : 's'를 포함하는 이름/텍스트\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수형식 확인하기\n",
    "df_ins.dtypes\n",
    "    ## int/float : 숫자\n",
    "    ## object : 문자열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 변수만 선택\n",
    "df_ins.select_dtypes(include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열 변수만 선택\n",
    "df_ins.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### [실습] Student performance 데이터 활용\n",
    "\n",
    "1. df_sp에서 수치형 변수만 선택\n",
    "2. df_sp에서 문자열 변수만 선택\n",
    "3. df_sp에서 이름에 'score'가 들어간 변수만 선택\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sp = pd.read_csv('data/StudentsPerformance.csv')\n",
    "df_sp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp.select_dtypes(include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp.filter(regex='score$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3.5. 조건을 활용한 관측치 선택\n",
    "\n",
    "SQL에서 WHERE 절이나 Excel의 Filter와 같이 데이터에서 부분을 선택할 때 조건을 활용하는 경우 많음  \n",
    "[ ]나 .loc[ ] 안에 조건식을 넣어서 조건과 일치하는 관측치만 선택 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 단계 : 조건 설정(결과는 True/False)\n",
    "    # bool 타입 Series \n",
    "df_ins['age'] < 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 단계 : []와 조건을 활용한 관측치 선택\n",
    "df_ins[df_ins['age'] < 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# &와 |를 활용한 조건 결합\n",
    "cond = (df_ins['age'] < 30) & (df_ins['sex'] == 'female')\n",
    "df_ins[cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins[(df_ins['age'] < 30) | (df_ins['sex'] == 'female')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "> 특히 비즈니스 데이터는 범주화, 그룹화된 변수들이 많고, 수많은 담당자들이 그 중 일부 범주, 그룹, 수준을 나눠서 운영하는 경우가 많습니다.  \n",
    "*isin()* 을 활용해서 내가 관심있는 범주인지 아닌지 포함여부에 대한 연산이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 region의 수준 목록 확인 및 관심 수준 선택\n",
    "df_ins['region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isin()을 활용한 특정 수준 관측치 선택\n",
    "cond1 = df_ins['region'].isin(['southeast','northwest'])\n",
    "# cond1 = (df_ins['region'] == 'southeast')  | (df_ins['region'] == 'northwest')\n",
    "cond1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins[cond1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### [실습]\n",
    "\n",
    "1. df_sp에서 math score가 90 이상인 관측치 선택\n",
    "2. df_sp에서 race/ethnicity가 'group D', 'group E'인 관측치 선택(isin() 활용)\n",
    "3. 1.과 2.를 동시에 만족하는 관측치 선택 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp.head()\n",
    "# math score 가 90이상이 관측치의 선택\n",
    "cond1 = df_sp['math score'] >= 90\n",
    "df_sp[cond1]\n",
    "\n",
    "# cond2 = (df_sp['race/ethnicity'] == 'group D') | (df_sp['race/ethnicity'] == 'group E')\n",
    "cond2 = df_sp['race/ethnicity'].isin(['group D', 'group E'])\n",
    "df_sp[cond2]\n",
    "\n",
    "# df_sp.loc[cond1]\n",
    "cond3 = cond1 & cond2\n",
    "df_sp[cond3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [참고] Series의 str 메서드 활용\n",
    "문자열 Series(한 변수)에서 str 함수를 활용하면 특정 단어를 포함하거나 특정 패턴과 일치하는 관측치를 선택 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp['parental level of education'].str.startswith('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp['parental level of education'].str.endswith('college')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp['parental level of education'].str.contains('degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### [참고] Series의 between 메서드 활용\n",
    "수치형 Series(한 변수)에서 *between()* 으로 특정 범위 내 관측치 선택 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp['math score'].between(80, 89.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 양쪽 끝 경계 포함 여부 지정 가능\n",
    "    # 'both', 'left', 'right'\n",
    "df_sp[df_sp['math score'].between(80, 90, inclusive='left')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### [참고] ~를 활용한 부정(True/False 반전)\n",
    "bool Series(True/False) 앞에 **~** 를 붙여서 True와 False를 뒤집기 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond1 = df_sp['math score'].between(80, 90, inclusive='left')\n",
    "cond1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "~cond1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp[~cond1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3.6. 함수를 활용한 부분 관측치 선택\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head( )와 tail()\n",
    "df_ins.head()\n",
    "df_ins.tail()\n",
    "df_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample( )의 활용\n",
    "df_ins.sample(frac=0.005)\n",
    "df_ins.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlargest( ), nsmallest( )로 상위/하위 관측치 선택\n",
    "df_ins.nlargest(10, 'charges')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins.nsmallest(10, 'charges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### [실습]\n",
    "\n",
    "1. df_sp에서 math score 상위 20 명 선택\n",
    "2. df_sp에서 writing score 하위 10명 선택\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp.nlargest(20, 'math score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp.nsmallest(10, 'writing score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3.7. 중복값 제거\n",
    "\n",
    "`drop_duplicates()`를 활용해서 중복값을 제거한 목록 생성 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins.drop_duplicates(subset=['sex','region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8. 관측치 정렬\n",
    "\n",
    "`sort_values()`를 활용해서 관측치를 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age 순 데이터 정렬\n",
    "df_ins.sort_values(['age', 'charges'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터는 영향 없음\n",
    "df_ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터의 정렬\n",
    "df_ins = df_ins.sort_values('age')\n",
    "df_ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내림차순 지정\n",
    "df_ins = df_ins.sort_values('age', ascending=False)\n",
    "df_ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복수 기준의 설정 \n",
    "df_ins.sort_values(['age', 'charges'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index를 활용한 정렬\n",
    "df_ins = df_ins.sort_index()\n",
    "df_ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "#### [실습] 데이터 df_sp 활용\n",
    "\n",
    "1. 전체 관측치를 'math score', 'reading score'의 내림차순으로 정렬해서 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp.sort_values(['math score', 'reading score'], ascending=[False, False]).iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp.nlargest(10, 'math score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End of script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
